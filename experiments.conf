train {
    SPLIT = train
    TASK = question-generation # either "question-generation" or "question-answering"
    ITERATIVE = ${ITERATIVE} # True (pass any string) or False(only empty string) to choose whether to generate all questions together or iteratively
    PLANNING = ${PLANNING} # only possible for question-generation at this point. Choose from 'equation', 'operator', or 'None'
    MODEL = t5 # t5 or bart
    MODEL_SIZE = large # small, base or large
    PRETRAINED_MODEL_PREFIX_PATH = ${PRETRAINED_MODEL_PREFIX_PATH} # leave empty when not used
    MODEL_NAME = ${train.MODEL}-${train.MODEL_SIZE}
    EXPORT_PREFIX_PATH = ${EXPORT_PREFIX_PATH}
    MODEL_CKPT_PATH = model_ckpts/${train.TASK}/${train.MODEL_NAME}-${train.PLANNING}-  # add custom path for test e.g. ./model_ckpts/question-generation/bart-large-True-1645526410599043904
    MODEL_IMPORT_PATH = ${MODEL_IMPORT_PATH}  # use "" or full path to model checkpoint to be loaded instead of pre-trained one, .e.g ./model_ckpts/question-generation/t5-large-operator-1648725459807811760
    LEARNING_RATE = 1e-5
    EPOCHS = 50
    EPOCHS = ${?EPOCHS}
    BATCH_SIZE = 32
    BATCH_SIZE = ${?BATCH_SIZE}
    LR_SCHEDULER = linear
    RL_EPOCHS = 1.00 # value <0,1>, if 0 - disabled, if 0.1 RL fine-tuning is done in the last 10% of epochs
    RL_EPOCHS = ${?RL_EPOCHS}
    TOP_P = 1.0 # for rl-sampling
    RETURN_SEQ = 25 # number of samples to generate during RL sampling
    RETURN_SEQ = ${?RETURN_SEQ}
    TEMPERATURE = 1.5 # for rl-sampling
    NUM_BEAMS = 4 # for rl-sampling
    VALID_EVERY_EPOCH = 1  # run validation every epoch
    VALID_EVERY_EPOCH = ${?VALID_EVERY_EPOCH}
    USE_GRADIENT_CLIPPING = True
    REWARD = ""
    REWARD = ${?REWARD}   # use any of the "fluency", "number", "qa", "combined" to use rewards
    QA_MODEL_PATH = ""
    QA_MODEL_PATH = ${?QA_MODEL_PATH} # path to the trained QA model
    QA_PARTIAL_REWARD = ""
    QA_PARTIAL_REWARD = ${?QA_PARTIAL_REWARD}
}

pre_train = ${train}{
    MODEL_CKPT_PATH = model_ckpts/${train.TASK}/pre-train/${train.MODEL_NAME}-${train.PLANNING}-
}

test = ${train}{
    SPLIT = test
    CRITIC = False # True or False depending on if pre-trained model is used or not.
    CRITIC = ${?CRITIC}
    CRITIC_MODEL_PATH = "" # add custom path for pretrained test model e.g. ./model_ckpts/question-generation/bart-large-True-1645526410599043904
    CRITIC_MODEL_PATH = ${?CRITIC_MODEL_PATH}
    write_prediction = True # write prediction in a file
    MODEL_IMPORT_PATH = ${MODEL_IMPORT_PATH} # full path to model checkpoint to be loaded instead of pre-trained one
}


